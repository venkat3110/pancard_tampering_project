# -*- coding: utf-8 -*-
"""PAN_CARD_tampering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vXt--cpPJXufYhKyJSinyom_3LkML5BN
"""

print("welcome to pancard tampering detection")

"""**PAN CARD TAMPERING DETECTION**

*The purpose of this project is to detect tampering of PAN card using computer vision this project will help different oraganization in detecting whether the id provided is original or not*
"""

from skimage.metrics import structural_similarity # similarity between original and provided
import imutils # grabing contours
import cv2
from PIL import Image # download and visualize image
import requests

!mkdir pan_card_tampering
!mkdir pan_card_tampering/image

# opening image and display
original = Image.open(requests.get("https://www.thestatesman.com/wp-content/uploads/2019/07/pan-card.jpg",stream=True).raw)
tampered = Image.open(requests.get('https://assets1.cleartax-cdn.com/s/img/20170526124335/Pan4.png',stream=True).raw)

# file format of the source file
print("original file format:",original.format)
print("tampered file format:",tampered.format)

# image size in pixels
print("original image size:",original.size)
print("tampered image size:",tampered.size)

# converting tampered format similar to original format
# saving image
original = original.resize((250,160))
print(original.size)
original.save('pan_card_tampering/image/original.png')
tampered = tampered.resize((250,160)) 
print(tampered.size)
tampered.save("pan_card_tampering/image/tampered.png")

original

tampered

# load the input images
original = cv2.imread('pan_card_tampering/image/original.png')
tampered = cv2.imread('pan_card_tampering/image/tampered.png')

"""**In many cases it is hard to interpret  the colored images by models sinci it has three channels .It is better to transform images into gray scale**"""

# reading images using opencv in gray format
original_gray = cv2.cvtColor(original,cv2.COLOR_BGR2GRAY)
tampered_gray = cv2.cvtColor(tampered,cv2.COLOR_BGR2GRAY)

# to compute structural similarity index and ensuring the difference between two images
(score,diff) = structural_similarity(original_gray,tampered_gray,full=True)
diff = (diff * 255).astype("uint8") # normalizing
print(f"SSIM: {score}")

# calculating threshold and contours
thresh = cv2.threshold(diff,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
contrs = cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
contrs = imutils.grab_contours(contrs)

"""bounding rectangle helps in finding th ratio of width of height of bounding reactangle of the object ,we compute the bounding box of the contour and then draw the bounding on both images to represent where the two images are different or not"""

for c in contrs:
  (x,y,w,h) = cv2.boundingRect(c)
  cv2.rectangle(original, (x,y), (x+w,y+h), (0,0,255), 2)
  cv2.rectangle(tampered, (x,y), (x+w,y+h), (0,0,255), 2)

# display original image with contour
print("original format image")
Image.fromarray(original)

# display tampered image with contour
print("tampered format image")
Image.fromarray(tampered)

# display difference image
print("difference image")
Image.fromarray(diff)

print("threshold image")
Image.fromarray(thresh)

"""Summary
 
 **Finding structural similarity of the images helped us in finding the difference of similarity in the shape of the images.similarly finding out the threshold and contours based on those threshold for the images converted into grayscale binary also helped us in shape analysis and recognition**
"""

